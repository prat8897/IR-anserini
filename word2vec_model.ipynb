{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "\n",
    "import os\n",
    "import gensim\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_tr=pd.read_table('queries.doctrain.tsv', header=None)\n",
    "q_tr.columns=['query_id','query_text']\n",
    "\n",
    "#long queries\n",
    "q_tr['len']=q_tr['query_text'].apply(lambda x: 1 if len(x) > 110 else np.nan)\n",
    "\n",
    "#short queries\n",
    "#q_tr['len']=q_tr['query_text'].apply(lambda x: 1 if len(x) > 25 and len(x) < 35 else np.nan)\n",
    "\n",
    "q_tr=q_tr.dropna()\n",
    "queries=q_tr.reset_index(drop=True).tail(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "top100=pd.read_table('msmarco-doctrain-top100', delimiter=' ', header=None)\n",
    "top100.columns=['query_id','f2','doc_id','rank','f5','f6']\n",
    "ranked100=top100[top100['query_id'].isin(queries['query_id'].unique())].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel=list(range(1,51))\n",
    "ranked100['rel']=ranked100['rank'].apply(lambda x: 1 if x in rel else np.nan)\n",
    "related_top50=ranked100.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts=dd.read_table('msmarco-docs.tsv', blocksize=100e6, header=None)\n",
    "all_texts.columns=['doc_id','f2','title','text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_corpus(res):\n",
    "    unique_doc_id=res['doc_id'].unique()\n",
    "    condition=all_texts['doc_id'].isin(unique_doc_id)\n",
    "    corpus=all_texts[condition].reset_index(drop=True)\n",
    "    corpus=corpus.drop(columns='f2')\n",
    "    return corpus\n",
    "\n",
    "testing_corpus=create_corpus(related_top50).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_corpus = all_texts.head(35000).values.tolist()\n",
    "clean_training_corpus = [x for x in training_corpus if str(x[3]) != 'nan']\n",
    "training_texts = [x[3] for x in clean_training_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [gensim.utils.simple_preprocess(x) for x in training_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(train_data, size=200, min_count=3, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(tokens):\n",
    "    embeddings = []\n",
    "    if len(tokens) > 0:\n",
    "        for token in tokens:\n",
    "            if token in model.wv.vocab:\n",
    "                embeddings.append(model.wv.word_vec(token))\n",
    "            else:\n",
    "                embeddings.append(np.random.rand(200))\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        return np.zeros(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_corpus['vector']=testing_corpus['text'].apply(lambda x: get_embedding(gensim.utils.simple_preprocess(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def ranking_ir(query):\n",
    "\n",
    "    vector=get_embedding(gensim.utils.simple_preprocess(query))\n",
    "\n",
    "    documents=testing_corpus[['doc_id', 'text']].copy()\n",
    "    documents['similarity']=testing_corpus['vector'].apply(lambda x: cosine_similarity(np.array(vector).reshape(1, -1),np.array(x).reshape(1, -1)).item())\n",
    "    documents.sort_values(by='similarity', ascending=False, inplace=True)\n",
    "  \n",
    "    return documents.head(20).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>text</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D2483074</td>\n",
       "      <td>40 terms daw2034Chapter 2: Britain and its Col...</td>\n",
       "      <td>0.919253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D1984850</td>\n",
       "      <td>52 terms minime1237APUSH Chapter 2: Beginnings...</td>\n",
       "      <td>0.915846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D1928899</td>\n",
       "      <td>The presidents during the last quarter ofthe n...</td>\n",
       "      <td>0.913805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D1581173</td>\n",
       "      <td>333 terms bayleekivett2Exam 1 Study Guide Lear...</td>\n",
       "      <td>0.911971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D3245559</td>\n",
       "      <td>1 Which of the following did NOT shape the cha...</td>\n",
       "      <td>0.905137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     doc_id                                               text  similarity\n",
       "0  D2483074  40 terms daw2034Chapter 2: Britain and its Col...    0.919253\n",
       "1  D1984850  52 terms minime1237APUSH Chapter 2: Beginnings...    0.915846\n",
       "2  D1928899  The presidents during the last quarter ofthe n...    0.913805\n",
       "3  D1581173  333 terms bayleekivett2Exam 1 Study Guide Lear...    0.911971\n",
       "4  D3245559  1 Which of the following did NOT shape the cha...    0.905137"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_example = 'which of the following were terms of the treaty of versailles?germany was occupied by allied troops.germany paid reparations.germany accepted sole responsibility for world war i.german territory was reduced in size.'\n",
    "top5_example = ranking_ir(query_example).head(5)\n",
    "top5_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_precision(query_id):\n",
    "    query = queries['query_text'].loc[queries['query_id'] == query_id].values[0]\n",
    "    top20 = ranking_ir(query)['doc_id'].values\n",
    "\n",
    "    related_docs = related_top50['doc_id'].loc[related_top50['query_id'] == query_id].values\n",
    "    is_related = [int(x in related_docs) for x in top20]\n",
    "\n",
    "    precision = []\n",
    "    for i in range(0,20):\n",
    "        if is_related[i]:\n",
    "            precision.append(np.sum(is_related[:i+1])/(i + 1))\n",
    "    return np.mean(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7120611392442039"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAP=queries['query_id'].apply(lambda x: get_average_precision(x)).mean()\n",
    "MAP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
